orchestrator:
  output_dir: orch_results/prod
  max_workers: 8
  retry: 3
  log_level: WARNING
drift_scan_schedule: daily
chunking:
  strategy: recursive
  fixed:
    chunk_size: 512
    overlap: 64
    min_length: 128
  semantic:
    min_length: 128
  recursive:
    max_chunk_size: 512
    min_length: 128
  sentence:
    min_length: 64
  token_based:
    chunk_size: 256
    overlap: 32
    min_length: 64
    tokenizer: dummy
  sliding_window:
    window_size: 256
    step_size: 128
    min_length: 64
  custom_heuristic:
    delimiter: "\n---\n"
    min_length: 64
    rules: {}
app:
  env: prod
  region: af-south-1
  account: "879584803102"
  resource_prefix: shieldcraft-prod
  log_level: WARN
  enable_feature_x: false
  # Cost and governance controls
  budget_limit_usd: 10000 # Monthly budget limit for prod environment
  cost_alert_thresholds:
    - 50
    - 80
    - 100
  cost_tags:
    project: shieldcraft-ai
    environment: prod
    owner: ai-solutions
  enable_cost_explorer: true
  enable_resource_tagging: true
  enable_budget_alerts: true

s3:
  buckets:
    - id: RawDataBucket
      name: shieldcraft-prod-raw
      versioned: true
      encryption: S3_MANAGED
      block_public_access: BLOCK_ALL
      removal_policy: RETAIN
      lifecycle_rules:
        - id: transition-raw-prod
          enabled: true
          transitions:
            - days: 90
              storage_class: STANDARD_IA
            - days: 180
              storage_class: GLACIER
          expiration_days: 1095
          abort_incomplete_multipart_upload_days: 7
    - id: ProcessedDataBucket
      name: shieldcraft-prod-processed
      versioned: true
      encryption: S3_MANAGED
      block_public_access: BLOCK_ALL
      removal_policy: RETAIN
      lifecycle_rules:
        - id: transition-processed-prod
          enabled: true
          transitions:
            - days: 90
              storage_class: STANDARD_IA
            - days: 180
              storage_class: GLACIER
          expiration_days: 1095
          abort_incomplete_multipart_upload_days: 7
    - id: AnalyticsDataBucket
      name: shieldcraft-prod-analytics
      versioned: true
      encryption: S3_MANAGED
      block_public_access: BLOCK_ALL
      lifecycle_rules:
        - id: transition-analytics-prod
          enabled: true
          transitions:
            - days: 90
              storage_class: STANDARD_IA
            - days: 180
              storage_class: GLACIER
          expiration_days: 1095
          abort_incomplete_multipart_upload_days: 7
  lifecycle_policy_days: 90
  enable_access_logs: true

networking:
  vpc_id: vpc-shieldcraft-prod
  cidr: "10.2.0.0/16"
  subnets:
    - id: subnet-pub-a
      cidr: "10.2.10.0/24"
      type: PUBLIC
    - id: subnet-priv-a
      cidr: "10.2.1.0/24"
      type: PRIVATE
    - id: subnet-priv-b
      cidr: "10.2.2.0/24"
      type: PRIVATE
    - id: subnet-priv-c
      cidr: "10.2.3.0/24"
      type: PRIVATE
  security_groups:
    - id: sg-msk
      description: Security group for MSK brokers
      allow_all_outbound: true
    - id: sg-lambda
      description: Security group for Lambda functions
      allow_all_outbound: true
    - id: sg-default
      description: Default security group for ShieldCraft prod VPC
      allow_all_outbound: true

msk:
  mode: managed # external (dev) | managed (staging/prod)
  security_group:
    id: sg-msk
    description: Security group for MSK brokers
    allow_all_outbound: true
  cluster:
    id: ShieldCraftMskCluster
    name: shieldcraft-msk-cluster-prod
    kafka_version: 3.5.1
    number_of_broker_nodes: 6
    instance_type: kafka.m5.large
    encryption_in_transit:
      client_broker: TLS
      in_cluster: true
    public_access: false
    vpc_subnet_ids:
      - subnet-priv-a
      - subnet-priv-b
      - subnet-priv-c
    security_group_ids:
      - sg-msk

sagemaker:
  mode: managed # local (dev) | managed
  training_instance_type: ml.m5.2xlarge
  inference_instance_type: ml.m5.xlarge
  endpoint_auto_scaling: true
  model_registry: shieldcraft-model-registry-prod
  multi_az_deployment: true
  data_capture_enabled: true
  model_monitoring_enabled: true

lambda_:
  functions:
    - id: MskTopicCreator
      description: Lambda to create Kafka topics after MSK cluster is ready
      handler: msk_topic_creator.lambda_handler
      runtime: python{{ PYTHON_VERSION }}
      memory_size: 512
      timeout: 120
      environment:
        MSK_CLUSTER_NAME: shieldcraft-msk-cluster-prod
        TOPICS:
          - name: events-ingest
            partitions: 6
            replication_factor: 3
          - name: audit-log
            partitions: 3
            replication_factor: 3
      vpc_subnet_ids:
        - subnet-priv-a
        - subnet-priv-b
        - subnet-priv-c
      security_group_ids:
        - sg-lambda
      policies:
        - kafka:DescribeCluster
        - kafka:GetBootstrapBrokers
        - kafka:CreateTopic
        - kafka:ListTopics
        - kafka:DescribeTopic

opensearch:
  mode: managed # none (dev) | managed | self_managed
  security_group:
    id: OpenSearchSecurityGroup
    description: Security group for OpenSearch
    allow_all_outbound: true
  domain:
    id: ShieldCraftOpenSearchDomain
    name: shieldcraft-opensearch-prod
    engine_version: OpenSearch_2.11
    cluster_config:
      instanceType: r6g.large.search
      instanceCount: 3
    node_to_node_encryption_options:
      enabled: true
    encryption_at_rest_options:
      enabled: true
    ebs_options:
      ebsEnabled: true
      volumeSize: 20
      volumeType: gp3

airbyte:
  mode: ecs_managed # local | ecs_scale_to_zero (dev) | ecs_managed
  deployment_type: ecs
  min_task_count: 2
  max_task_count: 6

data_quality:
  mode: managed # inline (dev) | managed
  dq_framework: deequ
  dq_schedule: cron(0 3 * * ? *)

lakeformation:
  admin_role: ShieldCraftLakeAdmin
  data_lake_location: s3://shieldcraft-prod-analytics
  buckets:
    - id: AnalyticsDataBucket
      name: shieldcraft-prod-analytics
    - id: RawDataBucket
      name: shieldcraft-prod-raw
    - id: ProcessedDataBucket
      name: shieldcraft-prod-processed
  permissions:
    - template: etl
      principal: GLUE_EXECUTION_ROLE_ARN
      resource_type: table
      resource:
        databaseName: shieldcraft_prod_db
        tableName: raw_data
    - template: admin
      principal: LAKEFORMATION_ADMIN_ROLE_ARN
      resource_type: database
      resource:
        databaseName: shieldcraft_prod_db
    - principal: SAGEMAKER_EXECUTION_ROLE_ARN
      resource_type: bucket
      resource:
        arn: arn:aws:s3:::shieldcraft-prod-analytics
      actions: ["DATA_LOCATION_ACCESS"]
tags:
  project: shieldcraft-ai
  environment: prod
  owner: ai-solutions
  cost_center: RND
  team: mlops
  compliance: standard
cloud_native_hardening:
  enable_cloudwatch_alarms: true
  alarm_email: ops@shieldcraft.ai
  config_rules:
    - s3-bucket-public-read-prohibited
    - iam-user-no-policies-check
glue:
  database_name: shieldcraft_prod_db
  crawler_schedule: cron(0 2 * * ? *)
  enable_data_quality: true
eventbridge:
  data_bus_name: shieldcraft-prod-data-bus
  security_bus_name: shieldcraft-prod-security-bus
  lambda_export_name: ProdMskTopicCreatorLambdaArn
  data_event_source: shieldcraft.data.prod

stepfunctions:
  state_machines:
    - id: DataIngestAndValidate
      name: shieldcraft-prod-data-ingest-validate
      role_arn: arn:aws:iam::123456789012:role/ShieldCraftStepFnRole
      comment: "Orchestrates data ingestion, validation, and error handling"
      definition:
        - id: IngestData
          type: Task
          resource: arn:aws:lambda:af-south-1:123456789012:function:IngestDataLambda
          next: ValidateData
          catch:
            - handler: HandleIngestError
              errors: ["States.ALL"]
        - id: ValidateData
          type: Task
          resource: arn:aws:lambda:af-south-1:123456789012:function:ValidateDataLambda
          next: IsValid
        - id: IsValid
          type: Choice
          choices:
            - condition: string_equals
              args: ["$.validationResult", "PASS"]
              next: Success
            - condition: string_equals
              args: ["$.validationResult", "FAIL"]
              next: HandleValidationError
          default: HandleValidationError
        - id: Success
          type: Pass
          end: true
        - id: HandleIngestError
          type: Pass
          end: true
        - id: HandleValidationError
          type: Pass
          end: true
    - id: BenchmarkAndValidate
      name: shieldcraft-prod-benchmark-validate
      role_arn: arn:aws:iam::123456789012:role/ShieldCraftStepFnRole
      comment: "Orchestrates BEIR/MTEB benchmarking and model validation (prod: full orchestration)"
      definition:
        - id: RunBEIRBenchmark
          type: Task
          resource: arn:aws:lambda:af-south-1:123456789012:function:RunBEIRBenchmarkLambda
          next: RunMTEBBenchmark
          catch:
            - handler: HandleBenchmarkError
              errors: ["States.ALL"]
        - id: RunMTEBBenchmark
          type: Task
          resource: arn:aws:lambda:af-south-1:123456789012:function:RunMTEBBenchmarkLambda
          next: ValidateBenchmarkResults
          catch:
            - handler: HandleBenchmarkError
              errors: ["States.ALL"]
        - id: ValidateBenchmarkResults
          type: Task
          resource: arn:aws:lambda:af-south-1:123456789012:function:ValidateBenchmarkResultsLambda
          next: Success
          catch:
            - handler: HandleBenchmarkError
              errors: ["States.ALL"]
        - id: Success
          type: Pass
          end: true
        - id: HandleBenchmarkError
          type: Pass
          end: true
ai_core:
  model_name: "mistralai/Mistral-7B-v0.1"
  quantize: true
  device: "cuda"
embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  quantize: true
  device: "cuda"
vector_store:
  db_host: "prod-db-host"
  db_port: 5432
  db_name: "shieldcraft_vectors_prod"
  db_user: "postgres"
  db_password: "REDACTED"
  table_name: "embeddings"
  batch_size: 100
beir:
  datasets: ["scifact", "trec-covid", "nfcorpus"]
  data_path: "./beir_datasets"
  output_path: "beir_results_prod.json"
  batch_size: 64
mteb:
  tasks: null
  output_path: "mteb_results_prod.json"
  batch_size: 64
